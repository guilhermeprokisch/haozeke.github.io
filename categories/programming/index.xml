<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>programming on Rohit Goswami</title>
    <link>https://rgoswami.me/categories/programming/</link>
    <description>Recent content in programming on Rohit Goswami</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;CC BY-NC-SA 4.0&lt;/a&gt;.</copyright>
    <lastBuildDate>Sun, 07 Jun 2020 04:24:00 +0000</lastBuildDate>
    
	<atom:link href="https://rgoswami.me/categories/programming/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Statistical Rethinking and Nix</title>
      <link>https://rgoswami.me/posts/rethinking-r-nix/</link>
      <pubDate>Sun, 07 Jun 2020 04:24:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/rethinking-r-nix/</guid>
      <description>This post describes how to set up a transparent automated setup for reproducible R workflows using nixpkgs, niv, and lorri. The explanatory example used throughout the post is one of setting up the rethinking package and running some examples from the excellent second edition of &amp;ldquo;Statistical Rethinking&amp;rdquo; by Richard McElreath.
 Background As detailed in an earlier post1, I had set up Nix to work with non-CRAN packages. If the rest of this section is unclear, please refer back to the earlier post.</description>
    </item>
    
    <item>
      <title>Nix with R and devtools</title>
      <link>https://rgoswami.me/posts/nix-r-devtools/</link>
      <pubDate>Sat, 06 Jun 2020 05:49:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/nix-r-devtools/</guid>
      <description>This post discusses briefly, the nix-shell environment for reproducible programming. In particular, there is an emphasis on extensions for installing and working with packages not in CRAN, i.e. packages off Github which are normally installed with devtools.
 Background The entire nix ecosystem is fantastic, and is the main packaging system used by d-SEAMS as well. Recently I began working through the excellent second edition of &amp;ldquo;Statistical Rethinking&amp;rdquo; by Richard McElreath1.</description>
    </item>
    
    <item>
      <title>Refactoring Dotfiles For Colemak</title>
      <link>https://rgoswami.me/posts/colemak-dots-refactor/</link>
      <pubDate>Sat, 02 May 2020 20:30:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/colemak-dots-refactor/</guid>
      <description>Background I have, in the past written about how I made the switch to Colemak. However, until recently, I was still trying to mimic the VIM keybindings from QWERTY. This is a post where I discuss the changes I made to ensure that I never have to stretch my fingers in odd ways again. The main idea is expressed well by vim-colemak.
Colemak layout: | QWERTY layout: `12345 67890-= Move around: | (instead of) `12345 67890-= qwfpg jluy;[]\  e | k qwert yuiop[]\  arstd HNEIo&amp;#39; h i | h l asdfg HJKL;&amp;#39; zxcvb km,.</description>
    </item>
    
    <item>
      <title>Pandoc to Orgmode with Babel</title>
      <link>https://rgoswami.me/posts/org-pandoc-babel/</link>
      <pubDate>Sat, 02 May 2020 16:39:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/org-pandoc-babel/</guid>
      <description>Background One of the best things about writing in orgmode is that we can embed and execute arbitrary code snippets. However, not all languages have an exporter, for obvious reasons. Somewhat surprisingly, there is no way to call pandoc on embedded snippets, which feels like a waste, especially when a whole bunch of documentation formats can be converted to orgmode with it.
Consider the following beautifully highlighted snippet of an rst (ReStructured Text) list table.</description>
    </item>
    
    <item>
      <title>Using Mathematica with Orgmode</title>
      <link>https://rgoswami.me/posts/org-mathematica/</link>
      <pubDate>Sun, 26 Apr 2020 20:01:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/org-mathematica/</guid>
      <description>Background I have been wanting to find a workflow which allows me to bypass writing a lot of TeX by hand for a while now. To that end I looked into using a computer algebra system (CAS). Naturally, my first choice was the FOSS Maxima (also because it uses Lisp under the hood). However, for all the reasons listed here, relating to its accuracy, which have not been fixed even though the post was over 5 years ago, I ended up having to go with the closed source Mathematica.</description>
    </item>
    
    <item>
      <title>Everyone Should Get an A - David MacKay</title>
      <link>https://rgoswami.me/posts/mackay-all-a/</link>
      <pubDate>Mon, 16 Mar 2020 02:24:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/mackay-all-a/</guid>
      <description>Background  I recently read this post written by the now deceased Prof. David MacKay&amp;nbsp;1 It should be read widely, however, given that it is distributed as a ps.gz which is then a .ps file, and thus probably inaccessible to many of the people who should read it, I decided to rework it for native online consumption (there is also a pdf) THIS IS NOT MY CONTENT&amp;nbsp;2 Now, enjoy the post  Everyone Should Get an A Imagine a University – call it Camwick – where all students arrive with straight A grades.</description>
    </item>
    
    <item>
      <title>Provisioning Dotfiles on an HPC</title>
      <link>https://rgoswami.me/posts/prov-dots/</link>
      <pubDate>Mon, 16 Mar 2020 00:06:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/prov-dots/</guid>
      <description>Background My dotfiles turned 4 years old a few months ago (since 9th Jan 2017) and remains one of my most frequently updated projects for obvious reasons. Going through the changes reminds me of a whole of posts I never got around to writing.
Anyway, recently I gained access to another HPC cluster, with a standard configuration (bash, old CentOS) and decided to track my provisioning steps. This is really a very streamlined experience by now, since I&amp;rsquo;ve used the same setup across scores of machines.</description>
    </item>
    
    <item>
      <title>ISLR :: Moving Beyond Linearity</title>
      <link>https://rgoswami.me/posts/islr-ch7/</link>
      <pubDate>Wed, 19 Feb 2020 09:47:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/islr-ch7/</guid>
      <description>Chapter VII - Moving Beyond Linearity All the questions are as per the ISL seventh printing.
Common libsUsed&amp;lt;-c(&amp;#34;dplyr&amp;#34;,&amp;#34;ggplot2&amp;#34;,&amp;#34;tidyverse&amp;#34;, &amp;#34;ISLR&amp;#34;,&amp;#34;caret&amp;#34;,&amp;#34;MASS&amp;#34;, &amp;#34;gridExtra&amp;#34;, &amp;#34;pls&amp;#34;,&amp;#34;latex2exp&amp;#34;,&amp;#34;data.table&amp;#34;) invisible(lapply(libsUsed, library, character.only = TRUE))## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──## ✔ tibble 2.1.3 ✔ purrr 0.3.3 ## ✔ tidyr 1.</description>
    </item>
    
    <item>
      <title>ISLR :: Linear Model Selection and Regularization</title>
      <link>https://rgoswami.me/posts/islr-ch6/</link>
      <pubDate>Wed, 19 Feb 2020 07:00:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/islr-ch6/</guid>
      <description>Chapter VI - Linear Model Selection and Regularization All the questions are as per the ISL seventh printing1.
Common Instead of using the standard functions, we will leverage the mlr3 package2.
#install.packages(&amp;#34;mlr3&amp;#34;,&amp;#34;data.table&amp;#34;,&amp;#34;mlr3viz&amp;#34;,&amp;#34;mlr3learners&amp;#34;) Actually for R version 3.6.2, the steps to get it working were a bit more involved.
Load ISLR and other libraries.
libsUsed&amp;lt;-c(&amp;#34;dplyr&amp;#34;,&amp;#34;ggplot2&amp;#34;,&amp;#34;tidyverse&amp;#34;, &amp;#34;ISLR&amp;#34;,&amp;#34;caret&amp;#34;,&amp;#34;MASS&amp;#34;, &amp;#34;gridExtra&amp;#34;, &amp;#34;pls&amp;#34;,&amp;#34;latex2exp&amp;#34;,&amp;#34;data.table&amp;#34;) invisible(lapply(libsUsed, library, character.only = TRUE))## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union## ── Attaching packages ─────────────────────────────────────── tidyverse 1.</description>
    </item>
    
    <item>
      <title>ISLR :: Resampling Methods</title>
      <link>https://rgoswami.me/posts/islr-ch5/</link>
      <pubDate>Tue, 18 Feb 2020 22:00:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/islr-ch5/</guid>
      <description>Chapter V - Resampling Methods All the questions are as per the ISL seventh printing1.
Common Instead of using the standard functions, we will leverage the mlr3 package2.
#install.packages(&amp;#34;mlr3&amp;#34;,&amp;#34;data.table&amp;#34;,&amp;#34;mlr3viz&amp;#34;,&amp;#34;mlr3learners&amp;#34;) Actually for R version 3.6.2, the steps to get it working were a bit more involved.
install.packages(&amp;#34;remotes&amp;#34;,&amp;#34;data.table&amp;#34;, &amp;#34;GGally&amp;#34;,&amp;#34;precerec&amp;#34;) # For plotslibrary(remotes) remotes::install_github(&amp;#34;mlr-org/mlr3&amp;#34;)## Skipping install of &amp;#39;mlr3&amp;#39; from a github remote, the SHA1 (fca21c10) has not changed since last install. ## Use `force = TRUE` to force installationremotes::install_github(&amp;#34;mlr-org/mlr3viz&amp;#34;)## Skipping install of &amp;#39;mlr3viz&amp;#39; from a github remote, the SHA1 (0b4ea273) has not changed since last install.</description>
    </item>
    
    <item>
      <title>ISLR :: Classification</title>
      <link>https://rgoswami.me/posts/islr-ch4/</link>
      <pubDate>Mon, 17 Feb 2020 15:28:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/islr-ch4/</guid>
      <description>Chapter IV - Classification All the questions are as per the ISL seventh printing&amp;nbsp;1.
Common Stuff Here I&amp;rsquo;ll load things I will be using throughout, mostly libraries.
libsUsed&amp;lt;-c(&amp;#34;dplyr&amp;#34;,&amp;#34;ggplot2&amp;#34;,&amp;#34;tidyverse&amp;#34;,&amp;#34;ISLR&amp;#34;,&amp;#34;caret&amp;#34;) invisible(lapply(libsUsed, library, character.only = TRUE))# # Attaching package: &amp;#39;dplyr&amp;#39;# The following objects are masked from &amp;#39;package:stats&amp;#39;: # # filter, lag# The following objects are masked from &amp;#39;package:base&amp;#39;: # # intersect, setdiff, setequal, union# ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──# ✔ tibble 2.</description>
    </item>
    
    <item>
      <title>Replacing Jupyter with Orgmode</title>
      <link>https://rgoswami.me/posts/jupyter-orgmode/</link>
      <pubDate>Thu, 13 Feb 2020 22:36:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/jupyter-orgmode/</guid>
      <description>Background  I dislike Jupyter notebooks (and JupyterHub) a lot EIN is really not much of a solution either  In the past I have written some posts on TeX with JupyterHub and discussed ways to use virtual Python with JupyterHub in a more reasonable manner.
However, I personally found that EIN was a huge pain to work with, and I mostly ended up working with the web-interface anyway.</description>
    </item>
    
    <item>
      <title>Poetry and Direnv</title>
      <link>https://rgoswami.me/posts/poetry-direnv/</link>
      <pubDate>Thu, 13 Feb 2020 21:36:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/poetry-direnv/</guid>
      <description>Background  I end up writing about using poetry a lot I almost always use direnv in real life too I don&amp;rsquo;t keep writing mini scripts in my .envrc  Honestly there&amp;rsquo;s nothing here anyone using the direnv wiki will find surprising, but then it is still neat to link back to.
Setting Up Poetry This essentially works by simply modifying the global .direnvrc which essentially gets sourced by every local .</description>
    </item>
    
    <item>
      <title>ISLR :: Multiple Linear Regression</title>
      <link>https://rgoswami.me/posts/islr-ch2-ch3/</link>
      <pubDate>Wed, 15 Jan 2020 05:28:00 +0000</pubDate>
      
      <guid>https://rgoswami.me/posts/islr-ch2-ch3/</guid>
      <description>Chapter II - Statistical Learning All the questions are as per the ISL seventh printing&amp;nbsp;1.
Question 2.8 - Pages 54-55 This exercise relates to the College data set, which can be found in the file College.csv. It contains a number of variables for \(777\) different universities and colleges in the US. The variables are
 Private : Public/private indicator Apps : Number of applications received Accept : Number of applicants accepted Enroll : Number of new students enrolled Top10perc : New students from top 10 % of high school class Top25perc : New students from top 25 % of high school class F.</description>
    </item>
    
  </channel>
</rss>